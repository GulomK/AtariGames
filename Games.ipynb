{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "716331e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install atari_py\n",
    "!pip3 install Box2D\n",
    "!pip3 install box2d-py\n",
    "!pip3 install \"stable-baselines3[extra]>=2.0.0a4\"\n",
    "!pip3 install gym\n",
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3733a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import cv2\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import StopTrainingOnRewardThreshold, EvalCallback\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a246ce4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1987 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1365        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008325238 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | -0.0223     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.99        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1248        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015918769 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.656      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1183        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014381671 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1148        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010206794 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1125        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018090382 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.27        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1111        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016032241 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 9.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1099        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010156763 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.553      |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 5.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012539049 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.528      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.91        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=399.60 +/- 116.19\n",
      "Episode length: 399.60 +/- 116.19\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 400        |\n",
      "|    mean_reward          | 400        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 20000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01217893 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.516     |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.36       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00652   |\n",
      "|    value_loss           | 4.67       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 1036  |\n",
      "|    iterations      | 10    |\n",
      "|    time_elapsed    | 19    |\n",
      "|    total_timesteps | 20480 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1030         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060195737 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.658        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 3.21         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1026        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597341 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.494      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.506       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1022        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015050242 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.474      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.978       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1019        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019738123 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 0.526       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1014        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013743547 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    value_loss           | 0.386       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1010        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008395275 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0654      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1007         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064281705 |\n",
      "|    clip_fraction        | 0.0992       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.129        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 0.356        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1003        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009464911 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 999         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017243017 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.063       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006562433 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0249      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 500.00  is above the threshold 500\n",
      "Episode: 1, score: [500.]\n",
      "Episode: 2, score: [500.]\n",
      "Episode: 3, score: [500.]\n",
      "Episode: 4, score: [500.]\n",
      "Episode: 5, score: [500.]\n",
      "Episode: 6, score: [500.]\n",
      "Episode: 7, score: [500.]\n",
      "Episode: 8, score: [500.]\n",
      "Episode: 9, score: [500.]\n",
      "Episode: 10, score: [500.]\n"
     ]
    }
   ],
   "source": [
    "class AtariGames:\n",
    "    def __init__(self, env_path, render_mode, path_save_best, path_save, video_path):\n",
    "        self.env_path = env_path\n",
    "        self.render_mode = render_mode\n",
    "        self.path_save_best = path_save_best\n",
    "        self.path_save = path_save\n",
    "        self.video_path = video_path\n",
    "\n",
    "    def make_env(self, which_env):\n",
    "        self.which_env = which_env\n",
    "        env = gym.make(self.env_path[self.which_env], render_mode=self.render_mode)\n",
    "        self.env = DummyVecEnv([lambda: env])\n",
    "        \n",
    "    def train_model(self, total_timesteps, episodes, policy_kwargs, reward_threshold, eval_freq):\n",
    "        stop_callback_func = StopTrainingOnRewardThreshold(reward_threshold=reward_threshold, verbose=1)\n",
    "        eval_callback = EvalCallback(self.env,\n",
    "                                      callback_on_new_best=stop_callback_func,\n",
    "                                      eval_freq=eval_freq,\n",
    "                                      best_model_save_path=self.path_save_best[0],\n",
    "                                      verbose=1)\n",
    "\n",
    "\n",
    "        self.model = PPO(\"MlpPolicy\", self.env,  verbose=1, policy_kwargs=policy_kwargs)\n",
    "        self.model.learn(total_timesteps=total_timesteps, callback=eval_callback)\n",
    "        evaluate_policy(self.model, self.env, n_eval_episodes=episodes, render=True)\n",
    "        \n",
    "        self.model.save(self.path_save[self.which_env])\n",
    "        del self.model\n",
    "        \n",
    "    def test_model(self, episodes, fps):\n",
    "        model = PPO.load(self.path_save[self.which_env], env=self.env)\n",
    "        observation= self.env.reset()\n",
    "        frame_size = (self.env.render().shape[1], self.env.render().shape[0])\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_writer = cv2.VideoWriter(self.video_path[self.which_env],  fourcc, fps, frame_size)\n",
    "        for i in range(1, episodes+1):\n",
    "            observation = self.env.reset()\n",
    "            score = 0\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                frame = self.env.render()\n",
    "                action, _ = model.predict(observation)\n",
    "                observation, reward, done, _ = self.env.step(action)\n",
    "                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                video_writer.write(frame_bgr)\n",
    "                score+=reward\n",
    "\n",
    "            print(f\"Episode: {i}, score: {score}\")\n",
    "        video_writer.release()\n",
    "        \n",
    "\n",
    "    \n",
    "# List of enviroments\n",
    "env = ('CartPole-v1', \"LunarLander-v2\", \"SpaceInvaders-v4\")\n",
    "\n",
    "# Render mode\n",
    "render_mode = \"rgb_array\"\n",
    "\n",
    "# Path to the best reward\n",
    "path_save_best = (\"CartPole-v1-BEST\", \"LunarLander-v2-BEST\", \"SpaceInvaders-v4\")\n",
    "\n",
    "# Path to model\n",
    "path_save = (\"cart_pole_model.zip\", \"lunar_landler.zip\", \"space_invaders.zip\")\n",
    "\n",
    "# Path to Video\n",
    "video_path = (\"CartPole-video.mp4\", \"LunarLander-video.mp4\", \"SpaceInvaders-video.mp4\")\n",
    "\n",
    "policy_kwargs = dict(pi=[64, 128, 128, 64], vf=[64, 128, 128, 64])\n",
    "act_fn=th.nn.ReLU\n",
    "custom_policy_kwargs = dict(net_arch=policy_kwargs, activation_fn=act_fn)\n",
    "\n",
    "games = AtariGames(env, render_mode, path_save_best, path_save, video_path)\n",
    "\n",
    "# CartPole game\n",
    "games.make_env(0)\n",
    "games.train_model(total_timesteps=100000, episodes=10, policy_kwargs=custom_policy_kwargs, reward_threshold=500, eval_freq= 20000)\n",
    "games.test_model(episodes=10, fps=35)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "777c2647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1545 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1113        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000422131 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.00101     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.000977   |\n",
      "|    value_loss           | 1.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1022        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008746324 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 327         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 986          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032718962 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 251          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 772          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 963          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033543925 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 196          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 732          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 945          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037598147 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    value_loss           | 329          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 933          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153593365 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 85.2         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 921         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004882396 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=-1001.24 +/- 490.79\n",
      "Episode length: 148.20 +/- 43.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 148         |\n",
      "|    mean_reward          | -1e+03      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 18000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015215866 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 888   |\n",
      "|    iterations      | 9     |\n",
      "|    time_elapsed    | 20    |\n",
      "|    total_timesteps | 18432 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 880         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010545123 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 877         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012500687 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 872         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014011923 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 848         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014570181 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 826        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01048064 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 45.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 802         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007950064 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 768         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008332891 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 746         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010013521 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.4         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=-32.44 +/- 26.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -32.4       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 36000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008989012 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.55        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 639   |\n",
      "|    iterations      | 18    |\n",
      "|    time_elapsed    | 57    |\n",
      "|    total_timesteps | 36864 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011431482 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007815085 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.04        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 7.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011065137 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 5.44        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069367727 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.65         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012889825 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 5.83        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013472773 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.56        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 7.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004061521 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 592        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01356774 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.78       |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    value_loss           | 20.1       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=25.90 +/- 84.40\n",
      "Episode length: 865.60 +/- 164.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 866         |\n",
      "|    mean_reward          | 25.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 54000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010731906 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 552   |\n",
      "|    iterations      | 27    |\n",
      "|    time_elapsed    | 100   |\n",
      "|    total_timesteps | 55296 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009729028 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.43        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 547        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 108        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00763435 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.881      |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.00809   |\n",
      "|    value_loss           | 5.49       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018704288 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.758       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    value_loss           | 3.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010570126 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 2.23        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122134155 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.977       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 538         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014131796 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 540        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 128        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10955571 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.303      |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | 0.00682    |\n",
      "|    value_loss           | 0.927      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022176118 |\n",
      "|    clip_fraction        | 0.072        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.91        |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | 0.000381     |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=94.32 +/- 123.21\n",
      "Episode length: 195.00 +/- 50.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 195          |\n",
      "|    mean_reward          | 94.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 72000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026802453 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.888       |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.16         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 78.8         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 542   |\n",
      "|    iterations      | 36    |\n",
      "|    time_elapsed    | 135   |\n",
      "|    total_timesteps | 73728 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036384726 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.904       |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.62         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008444733 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.97        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056916345 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.926       |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 53.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021141833 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.879       |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.48         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005622376 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.5         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011212815 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.948      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    value_loss           | 8.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 555         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013792872 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=93.27 +/- 184.82\n",
      "Episode length: 463.20 +/- 194.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 463         |\n",
      "|    mean_reward          | 93.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013230647 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.861      |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.754       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.000687   |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 547   |\n",
      "|    iterations      | 44    |\n",
      "|    time_elapsed    | 164   |\n",
      "|    total_timesteps | 90112 |\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005699401 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.963      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.54        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010786047 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.966      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.87        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    value_loss           | 4.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013824066 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.483       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004891794 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.388       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 549        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 182        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01890665 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.78      |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.663      |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00572   |\n",
      "|    value_loss           | 1.41       |\n",
      "----------------------------------------\n",
      "Episode: 1, score: [195.23044]\n",
      "Episode: 2, score: [69.2699]\n",
      "Episode: 3, score: [40.837753]\n",
      "Episode: 4, score: [146.76454]\n",
      "Episode: 5, score: [161.15285]\n",
      "Episode: 6, score: [135.07399]\n",
      "Episode: 7, score: [197.98755]\n",
      "Episode: 8, score: [283.23102]\n",
      "Episode: 9, score: [160.82962]\n",
      "Episode: 10, score: [160.1004]\n"
     ]
    }
   ],
   "source": [
    "# LunarLander game\n",
    "games.make_env(1)\n",
    "games.train_model(total_timesteps=100000, episodes=10, policy_kwargs=custom_policy_kwargs, reward_threshold=300, eval_freq= 18000)\n",
    "games.test_model(episodes=10, fps=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b804d1a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 258  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045278557 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | 0.00282      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    value_loss           | 8.67         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008326424 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013922412 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=105.00 +/- 0.00\n",
      "Episode length: 566.40 +/- 4.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 566          |\n",
      "|    mean_reward          | 105          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066384296 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.77         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    value_loss           | 66.6         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 46    |\n",
      "|    iterations      | 5     |\n",
      "|    time_elapsed    | 217   |\n",
      "|    total_timesteps | 10240 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009344889 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.15        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00995026 |\n",
      "|    clip_fraction        | 0.0808     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.75      |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.6        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0093    |\n",
      "|    value_loss           | 56.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012336035 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 427        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02077113 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.71      |\n",
      "|    explained_variance   | 0.69       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.32       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    value_loss           | 8.09       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=199.00 +/- 129.21\n",
      "Episode length: 894.40 +/- 238.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 894          |\n",
      "|    mean_reward          | 199          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155091435 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 41    |\n",
      "|    iterations      | 10    |\n",
      "|    time_elapsed    | 488   |\n",
      "|    total_timesteps | 20480 |\n",
      "------------------------------\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Episode: 1, score: [75.]\n",
      "Episode: 2, score: [195.]\n",
      "Episode: 3, score: [80.]\n",
      "Episode: 4, score: [210.]\n",
      "Episode: 5, score: [215.]\n",
      "Episode: 6, score: [140.]\n",
      "Episode: 7, score: [105.]\n",
      "Episode: 8, score: [120.]\n",
      "Episode: 9, score: [200.]\n",
      "Episode: 10, score: [75.]\n"
     ]
    }
   ],
   "source": [
    "# SpaceInvaders game\n",
    "games.make_env(2)\n",
    "games.train_model(total_timesteps=20000, episodes=10, policy_kwargs=custom_policy_kwargs, reward_threshold=300, eval_freq= 10000)\n",
    "games.test_model(episodes=10, fps=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7f9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
